{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import Dropout\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/jaina/Downloads/ESC-50-master/meta/esc50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir=\"C:/Users/jaina/Downloads/ESC-50-master/pro_dir_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for file in os.listdir(img_folder):    \n",
    "            image_path= os.path.join(img_folder, file)\n",
    "            img = image.load_img(image_path, target_size=(224, 224))\n",
    "            x = image.img_to_array(img)\n",
    "            x = preprocess_input(x)\n",
    "            img_data_array.append(x)\n",
    "            cat=df[df[\"filename\"].str[:-4]==file[:-4]].target.values[0]\n",
    "            class_name.append(cat)\n",
    "    return img_data_array, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the image array and class name\n",
    "img_data, class_name =create_dataset(processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(img_data, np.float32)\n",
    "y=np.array(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y , num_classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jaina\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\jaina\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "vgg19 False\n",
      "dropout_1 True\n",
      "dense_1 True\n",
      "dense_2 True\n",
      "dense_3 True\n",
      "dense_4 True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 512)               20024384  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 216)               110808    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 108)               23436     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 90)                9810      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                4550      \n",
      "=================================================================\n",
      "Total params: 20,172,988\n",
      "Trainable params: 148,604\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "VGG = VGG19(include_top=False, input_shape=(224,224,3),pooling='avg')\n",
    "model.add(VGG)\n",
    "VGG.summary()\n",
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(216,activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(108,activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(90,activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(50,activation='softmax'))\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jaina\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 192s 120ms/step - loss: 8.4378 - accuracy: 0.0444 - val_loss: 7.2859 - val_accuracy: 0.0825\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 157s 98ms/step - loss: 6.5318 - accuracy: 0.1412 - val_loss: 5.6422 - val_accuracy: 0.2375\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 158s 99ms/step - loss: 5.4091 - accuracy: 0.2081 - val_loss: 4.8258 - val_accuracy: 0.2650\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 158s 99ms/step - loss: 4.6435 - accuracy: 0.2806 - val_loss: 4.1570 - val_accuracy: 0.3625\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 160s 100ms/step - loss: 4.1168 - accuracy: 0.3469 - val_loss: 3.7695 - val_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 158s 99ms/step - loss: 3.7721 - accuracy: 0.3681 - val_loss: 3.5301 - val_accuracy: 0.4525\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 159s 99ms/step - loss: 3.4687 - accuracy: 0.4187 - val_loss: 3.2612 - val_accuracy: 0.4600\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 157s 98ms/step - loss: 3.2664 - accuracy: 0.4331 - val_loss: 3.1105 - val_accuracy: 0.4400\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 87s 54ms/step - loss: 3.1633 - accuracy: 0.4313 - val_loss: 2.9521 - val_accuracy: 0.4950\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 25s 16ms/step - loss: 3.0058 - accuracy: 0.4594 - val_loss: 2.9227 - val_accuracy: 0.5200\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 25s 16ms/step - loss: 2.9083 - accuracy: 0.4762 - val_loss: 2.7977 - val_accuracy: 0.4925\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 25s 16ms/step - loss: 2.8190 - accuracy: 0.4694 - val_loss: 2.6822 - val_accuracy: 0.5075\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 25s 16ms/step - loss: 2.7450 - accuracy: 0.4863 - val_loss: 2.6281 - val_accuracy: 0.5175\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 25s 16ms/step - loss: 2.6867 - accuracy: 0.4931 - val_loss: 2.5762 - val_accuracy: 0.5225\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 25s 16ms/step - loss: 2.6162 - accuracy: 0.5006 - val_loss: 2.5364 - val_accuracy: 0.5300\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.5762 - accuracy: 0.5019 - val_loss: 2.6471 - val_accuracy: 0.4800\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.4830 - accuracy: 0.5256 - val_loss: 2.4203 - val_accuracy: 0.5800\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.4530 - accuracy: 0.5325 - val_loss: 2.4153 - val_accuracy: 0.5450\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.4665 - accuracy: 0.5200 - val_loss: 2.4599 - val_accuracy: 0.5225\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.3853 - accuracy: 0.5381 - val_loss: 2.3820 - val_accuracy: 0.5475\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.3706 - accuracy: 0.5481 - val_loss: 2.4685 - val_accuracy: 0.5150\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.3220 - accuracy: 0.5275 - val_loss: 2.3382 - val_accuracy: 0.5500\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.3283 - accuracy: 0.5288 - val_loss: 2.3850 - val_accuracy: 0.5150\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.3251 - accuracy: 0.5344 - val_loss: 2.2865 - val_accuracy: 0.5425\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.2449 - accuracy: 0.5444 - val_loss: 2.3647 - val_accuracy: 0.5350\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.3031 - accuracy: 0.5425 - val_loss: 2.1876 - val_accuracy: 0.5750\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.2415 - accuracy: 0.5506 - val_loss: 2.2478 - val_accuracy: 0.5800\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.1990 - accuracy: 0.5512 - val_loss: 2.2133 - val_accuracy: 0.5500\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.1939 - accuracy: 0.5631 - val_loss: 2.2095 - val_accuracy: 0.5625\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.1369 - accuracy: 0.5550 - val_loss: 2.2181 - val_accuracy: 0.5425\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.1623 - accuracy: 0.5487 - val_loss: 2.2599 - val_accuracy: 0.5700\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.1457 - accuracy: 0.5706 - val_loss: 2.1483 - val_accuracy: 0.5925\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.1529 - accuracy: 0.5525 - val_loss: 2.1837 - val_accuracy: 0.5575\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.1802 - accuracy: 0.5475 - val_loss: 2.1943 - val_accuracy: 0.5575\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.1362 - accuracy: 0.5556 - val_loss: 2.1782 - val_accuracy: 0.5725\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.1279 - accuracy: 0.5706 - val_loss: 2.1183 - val_accuracy: 0.5750\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.0501 - accuracy: 0.5931 - val_loss: 2.1806 - val_accuracy: 0.5575\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.1385 - accuracy: 0.5481 - val_loss: 2.1281 - val_accuracy: 0.5675\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.0710 - accuracy: 0.5525 - val_loss: 2.2155 - val_accuracy: 0.5500\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.0913 - accuracy: 0.5794 - val_loss: 2.1771 - val_accuracy: 0.5500\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.0592 - accuracy: 0.5788 - val_loss: 2.0721 - val_accuracy: 0.5925\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.0469 - accuracy: 0.5881 - val_loss: 2.1074 - val_accuracy: 0.5650\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.0945 - accuracy: 0.5694 - val_loss: 2.0839 - val_accuracy: 0.5875\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.0145 - accuracy: 0.5938 - val_loss: 2.1443 - val_accuracy: 0.5475\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9931 - accuracy: 0.5831 - val_loss: 2.0530 - val_accuracy: 0.5750\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9572 - accuracy: 0.6137 - val_loss: 2.0520 - val_accuracy: 0.5750\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9890 - accuracy: 0.5913 - val_loss: 2.1677 - val_accuracy: 0.5975\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.0113 - accuracy: 0.5850 - val_loss: 2.2487 - val_accuracy: 0.5025\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9957 - accuracy: 0.5875 - val_loss: 2.0663 - val_accuracy: 0.5675\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9627 - accuracy: 0.6006 - val_loss: 2.0645 - val_accuracy: 0.5550\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 2.0060 - accuracy: 0.5913 - val_loss: 2.1215 - val_accuracy: 0.5350\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9665 - accuracy: 0.6050 - val_loss: 2.0876 - val_accuracy: 0.5625\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9485 - accuracy: 0.6069 - val_loss: 1.9833 - val_accuracy: 0.6075\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 27s 17ms/step - loss: 1.9345 - accuracy: 0.6119 - val_loss: 2.1140 - val_accuracy: 0.5600\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9410 - accuracy: 0.6019 - val_loss: 1.9986 - val_accuracy: 0.6200\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9557 - accuracy: 0.6056 - val_loss: 2.0819 - val_accuracy: 0.5575\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9510 - accuracy: 0.6069 - val_loss: 2.0301 - val_accuracy: 0.5900\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9369 - accuracy: 0.6100 - val_loss: 1.9892 - val_accuracy: 0.6250\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9190 - accuracy: 0.5987 - val_loss: 2.0764 - val_accuracy: 0.5875\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9310 - accuracy: 0.6031 - val_loss: 2.0203 - val_accuracy: 0.5750\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9085 - accuracy: 0.6175 - val_loss: 2.1534 - val_accuracy: 0.5650\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9127 - accuracy: 0.6006 - val_loss: 2.1343 - val_accuracy: 0.5750\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8912 - accuracy: 0.6094 - val_loss: 2.0778 - val_accuracy: 0.5700\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9228 - accuracy: 0.5975 - val_loss: 1.9459 - val_accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9445 - accuracy: 0.5981 - val_loss: 2.0860 - val_accuracy: 0.5625\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8760 - accuracy: 0.6075 - val_loss: 2.0194 - val_accuracy: 0.5925\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8761 - accuracy: 0.6056 - val_loss: 2.0822 - val_accuracy: 0.5600\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8881 - accuracy: 0.6044 - val_loss: 1.9838 - val_accuracy: 0.6025\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8545 - accuracy: 0.6288 - val_loss: 2.0501 - val_accuracy: 0.5800\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8858 - accuracy: 0.6131 - val_loss: 1.9836 - val_accuracy: 0.6025\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9133 - accuracy: 0.6169 - val_loss: 2.1454 - val_accuracy: 0.5425\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8669 - accuracy: 0.6137 - val_loss: 2.0040 - val_accuracy: 0.5725\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8660 - accuracy: 0.6175 - val_loss: 1.9549 - val_accuracy: 0.6125\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8372 - accuracy: 0.6200 - val_loss: 2.0248 - val_accuracy: 0.5900\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8365 - accuracy: 0.6194 - val_loss: 2.0762 - val_accuracy: 0.5550\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8518 - accuracy: 0.6119 - val_loss: 2.2129 - val_accuracy: 0.5225\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8499 - accuracy: 0.6256 - val_loss: 1.9941 - val_accuracy: 0.5550\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8557 - accuracy: 0.6112 - val_loss: 2.0636 - val_accuracy: 0.5550\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 26s 17ms/step - loss: 1.8235 - accuracy: 0.6288 - val_loss: 2.0126 - val_accuracy: 0.5800\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8551 - accuracy: 0.6031 - val_loss: 2.1431 - val_accuracy: 0.5450\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.9019 - accuracy: 0.6081 - val_loss: 2.0149 - val_accuracy: 0.5850\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8243 - accuracy: 0.6156 - val_loss: 1.9777 - val_accuracy: 0.5750\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8446 - accuracy: 0.6112 - val_loss: 2.1095 - val_accuracy: 0.5450\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8062 - accuracy: 0.6338 - val_loss: 2.0292 - val_accuracy: 0.5725\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8592 - accuracy: 0.6112 - val_loss: 2.1069 - val_accuracy: 0.5450\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8247 - accuracy: 0.6212 - val_loss: 1.9961 - val_accuracy: 0.5675\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8191 - accuracy: 0.6275 - val_loss: 2.0056 - val_accuracy: 0.5775\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.7776 - accuracy: 0.6425 - val_loss: 1.9885 - val_accuracy: 0.5900\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8147 - accuracy: 0.6175 - val_loss: 2.0049 - val_accuracy: 0.5725\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8120 - accuracy: 0.6125 - val_loss: 2.1695 - val_accuracy: 0.5275\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.7976 - accuracy: 0.6169 - val_loss: 1.9907 - val_accuracy: 0.5925\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8415 - accuracy: 0.6256 - val_loss: 1.9818 - val_accuracy: 0.5875\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.8142 - accuracy: 0.6200 - val_loss: 2.0313 - val_accuracy: 0.5725\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 26s 17ms/step - loss: 1.8059 - accuracy: 0.6325 - val_loss: 2.0481 - val_accuracy: 0.5625\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 27s 17ms/step - loss: 1.7569 - accuracy: 0.6463 - val_loss: 1.9725 - val_accuracy: 0.5825\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 27s 17ms/step - loss: 1.7545 - accuracy: 0.6338 - val_loss: 1.9517 - val_accuracy: 0.5850\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.7587 - accuracy: 0.6419 - val_loss: 1.9471 - val_accuracy: 0.5925\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.7920 - accuracy: 0.6250 - val_loss: 2.0042 - val_accuracy: 0.6000\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.7837 - accuracy: 0.6256 - val_loss: 1.9470 - val_accuracy: 0.6075\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 1.7684 - accuracy: 0.6294 - val_loss: 1.9440 - val_accuracy: 0.6050\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 512)               20024384  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 216)               110808    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 108)               23436     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 90)                9810      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                4550      \n",
      "=================================================================\n",
      "Total params: 20,172,988\n",
      "Trainable params: 148,604\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=100,batch_size=None,validation_data=(X_test,y_test))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
