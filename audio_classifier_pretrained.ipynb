{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import Dropout\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/jaina/Downloads/ESC-50-master/meta/esc50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir=\"C:/Users/jaina/Downloads/ESC-50-master/pro_dir_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for file in os.listdir(img_folder):    \n",
    "            image_path= os.path.join(img_folder, file)\n",
    "            img = image.load_img(image_path, target_size=(224, 224))\n",
    "            x = image.img_to_array(img)\n",
    "            x = preprocess_input(x)\n",
    "            img_data_array.append(x)\n",
    "            cat=df[df[\"filename\"].str[:-4]==file[:-4]].target.values[0]\n",
    "            class_name.append(cat)\n",
    "    return img_data_array, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the image array and class name\n",
    "img_data, class_name =create_dataset(processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(img_data, np.float32)\n",
    "y=np.array(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jaina\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\jaina\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "vgg16 False\n",
      "dropout_1 True\n",
      "dense_1 True\n",
      "dense_2 True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 216)               110808    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                10850     \n",
      "=================================================================\n",
      "Total params: 14,836,346\n",
      "Trainable params: 121,658\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "VGG = VGG16(include_top=False, input_shape=(224,224,3),pooling='avg')\n",
    "model.add(VGG)\n",
    "VGG.summary()\n",
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(216,activation='relu'))\n",
    "model.add(Dense(50,activation='softmax'))\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jaina\\anaconda3\\envs\\gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 26s 16ms/step - loss: 5.1931 - accuracy: 0.0675 - val_loss: 3.0892 - val_accuracy: 0.1975\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 3.2595 - accuracy: 0.1981 - val_loss: 2.5231 - val_accuracy: 0.3675\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 2.6803 - accuracy: 0.2931 - val_loss: 2.1340 - val_accuracy: 0.4300\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 2.3477 - accuracy: 0.3500 - val_loss: 1.9328 - val_accuracy: 0.4825\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 2.0323 - accuracy: 0.4437 - val_loss: 1.7135 - val_accuracy: 0.5375\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.8225 - accuracy: 0.4831 - val_loss: 1.6262 - val_accuracy: 0.5825\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.6601 - accuracy: 0.5256 - val_loss: 1.5397 - val_accuracy: 0.5725\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.5460 - accuracy: 0.5500 - val_loss: 1.5403 - val_accuracy: 0.5775\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.4731 - accuracy: 0.5675 - val_loss: 1.5331 - val_accuracy: 0.5825\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.4173 - accuracy: 0.5819 - val_loss: 1.3683 - val_accuracy: 0.6150\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.3030 - accuracy: 0.6144 - val_loss: 1.4369 - val_accuracy: 0.5950\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.2729 - accuracy: 0.6369 - val_loss: 1.3892 - val_accuracy: 0.6325\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.1982 - accuracy: 0.6275 - val_loss: 1.3484 - val_accuracy: 0.6250\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.1213 - accuracy: 0.6500 - val_loss: 1.3737 - val_accuracy: 0.6325\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.0654 - accuracy: 0.6725 - val_loss: 1.3344 - val_accuracy: 0.6500\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.0802 - accuracy: 0.6594 - val_loss: 1.4161 - val_accuracy: 0.6300\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 1.0441 - accuracy: 0.6769 - val_loss: 1.2981 - val_accuracy: 0.6550\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 0.9447 - accuracy: 0.7031 - val_loss: 1.3652 - val_accuracy: 0.6475\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.9089 - accuracy: 0.7075 - val_loss: 1.2793 - val_accuracy: 0.6675\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.9080 - accuracy: 0.7244 - val_loss: 1.2539 - val_accuracy: 0.6675\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.8931 - accuracy: 0.7206 - val_loss: 1.3123 - val_accuracy: 0.6550\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.8780 - accuracy: 0.7325 - val_loss: 1.2756 - val_accuracy: 0.6825\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.8294 - accuracy: 0.7331 - val_loss: 1.2809 - val_accuracy: 0.6775\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.7889 - accuracy: 0.7544 - val_loss: 1.2766 - val_accuracy: 0.6625\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.7680 - accuracy: 0.7556 - val_loss: 1.2467 - val_accuracy: 0.6750\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.7227 - accuracy: 0.7719 - val_loss: 1.3145 - val_accuracy: 0.6625\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.7644 - accuracy: 0.7581 - val_loss: 1.2939 - val_accuracy: 0.6700\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.7052 - accuracy: 0.7800 - val_loss: 1.3018 - val_accuracy: 0.6725\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.7051 - accuracy: 0.7850 - val_loss: 1.3045 - val_accuracy: 0.6625\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.7132 - accuracy: 0.7850 - val_loss: 1.2713 - val_accuracy: 0.6675\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.6173 - accuracy: 0.8006 - val_loss: 1.2317 - val_accuracy: 0.6950\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.6547 - accuracy: 0.7875 - val_loss: 1.2667 - val_accuracy: 0.6825\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.6211 - accuracy: 0.8044 - val_loss: 1.2608 - val_accuracy: 0.6800\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.6763 - accuracy: 0.7850 - val_loss: 1.2604 - val_accuracy: 0.6675\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.6143 - accuracy: 0.8000 - val_loss: 1.2389 - val_accuracy: 0.6975\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.6754 - accuracy: 0.7763 - val_loss: 1.1950 - val_accuracy: 0.6950\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5686 - accuracy: 0.8062 - val_loss: 1.3013 - val_accuracy: 0.6875\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.6192 - accuracy: 0.7950 - val_loss: 1.2900 - val_accuracy: 0.6900\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5633 - accuracy: 0.8194 - val_loss: 1.2279 - val_accuracy: 0.6925\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.6068 - accuracy: 0.8100 - val_loss: 1.2038 - val_accuracy: 0.7050\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5479 - accuracy: 0.8256 - val_loss: 1.2931 - val_accuracy: 0.6800\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5667 - accuracy: 0.8169 - val_loss: 1.2444 - val_accuracy: 0.6975\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5319 - accuracy: 0.8375 - val_loss: 1.2759 - val_accuracy: 0.6875\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5193 - accuracy: 0.8288 - val_loss: 1.3004 - val_accuracy: 0.6825\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5342 - accuracy: 0.8381 - val_loss: 1.2598 - val_accuracy: 0.6925\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5290 - accuracy: 0.8344 - val_loss: 1.2993 - val_accuracy: 0.6875\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5220 - accuracy: 0.8288 - val_loss: 1.3754 - val_accuracy: 0.6500\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5300 - accuracy: 0.8300 - val_loss: 1.4315 - val_accuracy: 0.6850\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.5322 - accuracy: 0.8331 - val_loss: 1.2426 - val_accuracy: 0.7275\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4630 - accuracy: 0.8431 - val_loss: 1.3440 - val_accuracy: 0.7025\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4623 - accuracy: 0.8469 - val_loss: 1.3255 - val_accuracy: 0.7000\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4457 - accuracy: 0.8569 - val_loss: 1.3698 - val_accuracy: 0.6875\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4820 - accuracy: 0.8494 - val_loss: 1.2965 - val_accuracy: 0.6975\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4900 - accuracy: 0.8406 - val_loss: 1.3285 - val_accuracy: 0.7175\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4567 - accuracy: 0.8525 - val_loss: 1.2306 - val_accuracy: 0.6975\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4332 - accuracy: 0.8644 - val_loss: 1.3257 - val_accuracy: 0.6800\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4329 - accuracy: 0.8587 - val_loss: 1.3516 - val_accuracy: 0.6975\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4062 - accuracy: 0.8669 - val_loss: 1.3475 - val_accuracy: 0.7025\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4487 - accuracy: 0.8537 - val_loss: 1.3562 - val_accuracy: 0.6900\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3897 - accuracy: 0.8756 - val_loss: 1.4266 - val_accuracy: 0.6900\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4005 - accuracy: 0.8631 - val_loss: 1.3274 - val_accuracy: 0.6950\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4113 - accuracy: 0.8644 - val_loss: 1.3129 - val_accuracy: 0.7175\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3798 - accuracy: 0.8756 - val_loss: 1.3639 - val_accuracy: 0.6875\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3811 - accuracy: 0.8744 - val_loss: 1.3512 - val_accuracy: 0.6950\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3871 - accuracy: 0.8769 - val_loss: 1.3062 - val_accuracy: 0.6925\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.4291 - accuracy: 0.8656 - val_loss: 1.2288 - val_accuracy: 0.7175\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3673 - accuracy: 0.8731 - val_loss: 1.3551 - val_accuracy: 0.7075\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3853 - accuracy: 0.8637 - val_loss: 1.3125 - val_accuracy: 0.7000\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3959 - accuracy: 0.8706 - val_loss: 1.3829 - val_accuracy: 0.6975\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3804 - accuracy: 0.8800 - val_loss: 1.2997 - val_accuracy: 0.7150\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3536 - accuracy: 0.8881 - val_loss: 1.3251 - val_accuracy: 0.6950\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3792 - accuracy: 0.8769 - val_loss: 1.3921 - val_accuracy: 0.6950\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3768 - accuracy: 0.8800 - val_loss: 1.4562 - val_accuracy: 0.7050\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3509 - accuracy: 0.8794 - val_loss: 1.4785 - val_accuracy: 0.6975\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3547 - accuracy: 0.8838 - val_loss: 1.4526 - val_accuracy: 0.7000\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3683 - accuracy: 0.8769 - val_loss: 1.4020 - val_accuracy: 0.7125\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 21s 13ms/step - loss: 0.3680 - accuracy: 0.8819 - val_loss: 1.3634 - val_accuracy: 0.6900\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3426 - accuracy: 0.8863 - val_loss: 1.3616 - val_accuracy: 0.6950\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3406 - accuracy: 0.8913 - val_loss: 1.3927 - val_accuracy: 0.7050\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3618 - accuracy: 0.8856 - val_loss: 1.3610 - val_accuracy: 0.6900\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3226 - accuracy: 0.8938 - val_loss: 1.2608 - val_accuracy: 0.7275\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3581 - accuracy: 0.8819 - val_loss: 1.3362 - val_accuracy: 0.7075\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3475 - accuracy: 0.8831 - val_loss: 1.3826 - val_accuracy: 0.6975\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.2788 - accuracy: 0.9069 - val_loss: 1.3489 - val_accuracy: 0.7150\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.3326 - accuracy: 0.8869 - val_loss: 1.3355 - val_accuracy: 0.7225\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.2955 - accuracy: 0.9112 - val_loss: 1.3611 - val_accuracy: 0.6925\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.2902 - accuracy: 0.9056 - val_loss: 1.3402 - val_accuracy: 0.6900\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3513 - accuracy: 0.8894 - val_loss: 1.3914 - val_accuracy: 0.6950\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3314 - accuracy: 0.8963 - val_loss: 1.4550 - val_accuracy: 0.6875\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3310 - accuracy: 0.8913 - val_loss: 1.3556 - val_accuracy: 0.7275\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.2977 - accuracy: 0.9081 - val_loss: 1.3210 - val_accuracy: 0.7300\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3355 - accuracy: 0.8831 - val_loss: 1.2902 - val_accuracy: 0.7075\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3415 - accuracy: 0.8863 - val_loss: 1.2780 - val_accuracy: 0.7025\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3308 - accuracy: 0.8900 - val_loss: 1.3671 - val_accuracy: 0.6900\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3047 - accuracy: 0.8950 - val_loss: 1.2971 - val_accuracy: 0.6900\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.2996 - accuracy: 0.9019 - val_loss: 1.3523 - val_accuracy: 0.7125\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.3150 - accuracy: 0.8925 - val_loss: 1.4420 - val_accuracy: 0.7075\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.2666 - accuracy: 0.9119 - val_loss: 1.3917 - val_accuracy: 0.7325\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.2945 - accuracy: 0.9050 - val_loss: 1.4243 - val_accuracy: 0.7275\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 20s 13ms/step - loss: 0.2680 - accuracy: 0.9038 - val_loss: 1.4117 - val_accuracy: 0.7200\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 216)               110808    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                10850     \n",
      "=================================================================\n",
      "Total params: 14,836,346\n",
      "Trainable params: 121,658\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=100,batch_size=None,validation_data=(X_test,y_test))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
